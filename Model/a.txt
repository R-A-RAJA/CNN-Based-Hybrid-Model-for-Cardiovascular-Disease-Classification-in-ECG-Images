ℹ️ No saved model found. Starting fresh training.
📌 Training will continue from last best validation accuracy: 0.0000
/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
Epoch 1/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 0s 9s/step - accuracy: 0.2431 - loss: 49.4002 WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 

🏆 Validation accuracy improved from 0.0000 to 0.2581. Saving model...
24/24 ━━━━━━━━━━━━━━━━━━━━ 242s 10s/step - accuracy: 0.2448 - loss: 48.6761 - val_accuracy: 0.2581 - val_loss: 732.5563
Epoch 2/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 0s 9s/step - accuracy: 0.3462 - loss: 8.6624WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 

🏆 Validation accuracy improved from 0.2581 to 0.3065. Saving model...
24/24 ━━━━━━━━━━━━━━━━━━━━ 234s 10s/step - accuracy: 0.3460 - loss: 8.6110 - val_accuracy: 0.3065 - val_loss: 291.9393
Epoch 3/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 230s 10s/step - accuracy: 0.4770 - loss: 3.5493 - val_accuracy: 0.1828 - val_loss: 234.1785
Epoch 4/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 230s 10s/step - accuracy: 0.4424 - loss: 3.8743 - val_accuracy: 0.1828 - val_loss: 139.5264
Epoch 5/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 230s 10s/step - accuracy: 0.5404 - loss: 2.3271 - val_accuracy: 0.1828 - val_loss: 100.8846
Epoch 6/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 263s 10s/step - accuracy: 0.5920 - loss: 2.1751 - val_accuracy: 0.1828 - val_loss: 102.0589
Epoch 7/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 262s 10s/step - accuracy: 0.6532 - loss: 1.8400 - val_accuracy: 0.1828 - val_loss: 47.4033
Epoch 8/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 232s 10s/step - accuracy: 0.6949 - loss: 1.4100 - val_accuracy: 0.1828 - val_loss: 31.8162
Epoch 9/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 233s 10s/step - accuracy: 0.6861 - loss: 1.4347 - val_accuracy: 0.3065 - val_loss: 20.4015
Epoch 10/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 260s 10s/step - accuracy: 0.7142 - loss: 1.4240 - val_accuracy: 0.2366 - val_loss: 12.1134
Epoch 11/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 262s 10s/step - accuracy: 0.6994 - loss: 1.9020 - val_accuracy: 0.1828 - val_loss: 33.4792
Epoch 12/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 229s 10s/step - accuracy: 0.6403 - loss: 1.9217 - val_accuracy: 0.1828 - val_loss: 23.8401
Epoch 13/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 231s 10s/step - accuracy: 0.7702 - loss: 1.1637 - val_accuracy: 0.1828 - val_loss: 21.2728
Epoch 14/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 230s 10s/step - accuracy: 0.7822 - loss: 0.8146 - val_accuracy: 0.1828 - val_loss: 12.6017
Epoch 15/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 0s 9s/step - accuracy: 0.7898 - loss: 0.8928WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 

🏆 Validation accuracy improved from 0.3065 to 0.3656. Saving model...
24/24 ━━━━━━━━━━━━━━━━━━━━ 231s 10s/step - accuracy: 0.7892 - loss: 0.8999 - val_accuracy: 0.3656 - val_loss: 7.5739
Epoch 16/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 231s 10s/step - accuracy: 0.6955 - loss: 1.4321 - val_accuracy: 0.1882 - val_loss: 6.8076
Epoch 17/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 231s 10s/step - accuracy: 0.7761 - loss: 1.0891 - val_accuracy: 0.3065 - val_loss: 6.7127
Epoch 18/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 0s 9s/step - accuracy: 0.8313 - loss: 0.7230WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 

🏆 Validation accuracy improved from 0.3656 to 0.5054. Saving model...
24/24 ━━━━━━━━━━━━━━━━━━━━ 231s 10s/step - accuracy: 0.8320 - loss: 0.7193 - val_accuracy: 0.5054 - val_loss: 4.6915
Epoch 19/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 260s 10s/step - accuracy: 0.8186 - loss: 0.8371 - val_accuracy: 0.5000 - val_loss: 2.3363
Epoch 20/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 229s 10s/step - accuracy: 0.8316 - loss: 0.6338 - val_accuracy: 0.2581 - val_loss: 17.5631
Epoch 21/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 0s 9s/step - accuracy: 0.8360 - loss: 0.7216WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 

🏆 Validation accuracy improved from 0.5054 to 0.5108. Saving model...
24/24 ━━━━━━━━━━━━━━━━━━━━ 231s 10s/step - accuracy: 0.8361 - loss: 0.7200 - val_accuracy: 0.5108 - val_loss: 5.9460
Epoch 22/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 261s 10s/step - accuracy: 0.8501 - loss: 0.7461 - val_accuracy: 0.4301 - val_loss: 8.4168
Epoch 23/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 230s 10s/step - accuracy: 0.8377 - loss: 0.6952 - val_accuracy: 0.2043 - val_loss: 8.1480
Epoch 24/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 228s 10s/step - accuracy: 0.8423 - loss: 0.6317 - val_accuracy: 0.1935 - val_loss: 12.3225
Epoch 25/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 231s 10s/step - accuracy: 0.8464 - loss: 0.6770 - val_accuracy: 0.2849 - val_loss: 9.0251
Epoch 26/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 259s 9s/step - accuracy: 0.8698 - loss: 0.5307 - val_accuracy: 0.4086 - val_loss: 8.9699
Epoch 27/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 0s 9s/step - accuracy: 0.8974 - loss: 0.3479WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 

🏆 Validation accuracy improved from 0.5108 to 0.5376. Saving model...
24/24 ━━━━━━━━━━━━━━━━━━━━ 231s 10s/step - accuracy: 0.8977 - loss: 0.3491 - val_accuracy: 0.5376 - val_loss: 3.1954
Epoch 28/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 259s 9s/step - accuracy: 0.8978 - loss: 0.3947 - val_accuracy: 0.2151 - val_loss: 13.7559
Epoch 29/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 227s 9s/step - accuracy: 0.9122 - loss: 0.3644 - val_accuracy: 0.4301 - val_loss: 4.8313
Epoch 30/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 0s 9s/step - accuracy: 0.8676 - loss: 0.5296WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 

🏆 Validation accuracy improved from 0.5376 to 0.7688. Saving model...
24/24 ━━━━━━━━━━━━━━━━━━━━ 230s 10s/step - accuracy: 0.8679 - loss: 0.5285 - val_accuracy: 0.7688 - val_loss: 1.3082
Epoch 31/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 241s 10s/step - accuracy: 0.8964 - loss: 0.4945 - val_accuracy: 0.4355 - val_loss: 5.3241
Epoch 32/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 228s 10s/step - accuracy: 0.9330 - loss: 0.2013 - val_accuracy: 0.4462 - val_loss: 6.4023
Epoch 33/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 260s 9s/step - accuracy: 0.8998 - loss: 0.3654 - val_accuracy: 0.3226 - val_loss: 8.9315
Epoch 34/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 229s 9s/step - accuracy: 0.9225 - loss: 0.3527 - val_accuracy: 0.4032 - val_loss: 7.8575
Epoch 35/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 0s 9s/step - accuracy: 0.8869 - loss: 0.4362WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 

🏆 Validation accuracy improved from 0.7688 to 0.7957. Saving model...
24/24 ━━━━━━━━━━━━━━━━━━━━ 230s 10s/step - accuracy: 0.8871 - loss: 0.4363 - val_accuracy: 0.7957 - val_loss: 1.4947
Epoch 36/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 228s 9s/step - accuracy: 0.9195 - loss: 0.3725 - val_accuracy: 0.6344 - val_loss: 3.3013
Epoch 37/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 263s 9s/step - accuracy: 0.9023 - loss: 0.3658 - val_accuracy: 0.6989 - val_loss: 1.6920
Epoch 38/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 0s 9s/step - accuracy: 0.9248 - loss: 0.2932WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 

🏆 Validation accuracy improved from 0.7957 to 0.8710. Saving model...
24/24 ━━━━━━━━━━━━━━━━━━━━ 228s 10s/step - accuracy: 0.9251 - loss: 0.2918 - val_accuracy: 0.8710 - val_loss: 0.4861
Epoch 39/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 261s 9s/step - accuracy: 0.9205 - loss: 0.2859 - val_accuracy: 0.7473 - val_loss: 1.4188
Epoch 40/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 262s 9s/step - accuracy: 0.9647 - loss: 0.1069 - val_accuracy: 0.8280 - val_loss: 1.2078
Epoch 41/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 0s 9s/step - accuracy: 0.9493 - loss: 0.1753WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 

🏆 Validation accuracy improved from 0.8710 to 0.9624. Saving model...
24/24 ━━━━━━━━━━━━━━━━━━━━ 228s 10s/step - accuracy: 0.9491 - loss: 0.1758 - val_accuracy: 0.9624 - val_loss: 0.1384
Epoch 42/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 229s 10s/step - accuracy: 0.9739 - loss: 0.0716 - val_accuracy: 0.9409 - val_loss: 0.2572
Epoch 43/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 260s 9s/step - accuracy: 0.9334 - loss: 0.2393 - val_accuracy: 0.3925 - val_loss: 8.4017
Epoch 44/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 230s 10s/step - accuracy: 0.9282 - loss: 0.2289 - val_accuracy: 0.7527 - val_loss: 1.8003
Epoch 45/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 232s 10s/step - accuracy: 0.9668 - loss: 0.1126 - val_accuracy: 0.6989 - val_loss: 1.9162
Epoch 46/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 229s 10s/step - accuracy: 0.9001 - loss: 0.3443 - val_accuracy: 0.8871 - val_loss: 0.7076
Epoch 47/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 229s 10s/step - accuracy: 0.9463 - loss: 0.1730 - val_accuracy: 0.5108 - val_loss: 4.5667
Epoch 48/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 230s 10s/step - accuracy: 0.9078 - loss: 0.3052 - val_accuracy: 0.9462 - val_loss: 0.2748
Epoch 49/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 262s 10s/step - accuracy: 0.9412 - loss: 0.1925 - val_accuracy: 0.9086 - val_loss: 0.4633
Epoch 50/50
24/24 ━━━━━━━━━━━━━━━━━━━━ 234s 10s/step - accuracy: 0.9618 - loss: 0.1234 - val_accuracy: 0.9570 - val_loss: 0.1470
WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
🏆 Final best validation accuracy achieved: 0.9624

WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
24/24 ━━━━━━━━━━━━━━━━━━━━ 37s 2s/step
6/6 ━━━━━━━━━━━━━━━━━━━━ 10s 2s/step

Training and evaluating SVM...
SVM Accuracy: 96.24%

Classification Report:
              precision    recall  f1-score   support

      Normal       0.98      0.96      0.97        57
    Abnormal       0.96      0.94      0.95        47
          MI       1.00      1.00      1.00        48
  History_MI       0.89      0.94      0.91        34

    accuracy                           0.96       186
   macro avg       0.96      0.96      0.96       186
weighted avg       0.96      0.96      0.96       186

Confusion Matrix:
[[55  0  0  2]
 [ 1 44  0  2]
 [ 0  0 48  0]
 [ 0  2  0 32]]

SVM accuracy improved from 0.00% to 96.24%. Saving model...

Training and evaluating K-NN...
K-NN Accuracy: 96.24%

Classification Report:
              precision    recall  f1-score   support

      Normal       1.00      0.96      0.98        57
    Abnormal       0.96      0.94      0.95        47
          MI       1.00      1.00      1.00        48
  History_MI       0.86      0.94      0.90        34

    accuracy                           0.96       186
   macro avg       0.96      0.96      0.96       186
weighted avg       0.96      0.96      0.96       186

Confusion Matrix:
[[55  0  0  2]
 [ 0 44  0  3]
 [ 0  0 48  0]
 [ 0  2  0 32]]

K-NN accuracy improved from 0.00% to 96.24%. Saving model...

Training and evaluating Decision Tree...
Decision Tree Accuracy: 93.01%

Classification Report:
              precision    recall  f1-score   support

      Normal       0.96      0.89      0.93        57
    Abnormal       0.87      0.85      0.86        47
          MI       1.00      1.00      1.00        48
  History_MI       0.87      1.00      0.93        34

    accuracy                           0.93       186
   macro avg       0.93      0.94      0.93       186
weighted avg       0.93      0.93      0.93       186

Confusion Matrix:
[[51  6  0  0]
 [ 2 40  0  5]
 [ 0  0 48  0]
 [ 0  0  0 34]]

Decision Tree accuracy improved from 0.00% to 93.01%. Saving model...

Training and evaluating Random Forest...
Random Forest Accuracy: 97.31%

Classification Report:
              precision    recall  f1-score   support

      Normal       0.98      0.96      0.97        57
    Abnormal       1.00      0.94      0.97        47
          MI       1.00      1.00      1.00        48
  History_MI       0.89      1.00      0.94        34

    accuracy                           0.97       186
   macro avg       0.97      0.98      0.97       186
weighted avg       0.98      0.97      0.97       186

Confusion Matrix:
[[55  0  0  2]
 [ 1 44  0  2]
 [ 0  0 48  0]
 [ 0  0  0 34]]

Random Forest accuracy improved from 0.00% to 97.31%. Saving model...

Training and evaluating Naive Bayes...
Naive Bayes Accuracy: 96.24%

Classification Report:
              precision    recall  f1-score   support

      Normal       0.98      0.96      0.97        57
    Abnormal       0.96      0.94      0.95        47
          MI       1.00      1.00      1.00        48
  History_MI       0.89      0.94      0.91        34

    accuracy                           0.96       186
   macro avg       0.96      0.96      0.96       186
weighted avg       0.96      0.96      0.96       186

Confusion Matrix:
[[55  0  0  2]
 [ 1 44  0  2]
 [ 0  0 48  0]
 [ 0  2  0 32]]

Naive Bayes accuracy improved from 0.00% to 96.24%. Saving model...

Training and evaluating XGBoost...
XGBoost Accuracy: 97.85%

Classification Report:
              precision    recall  f1-score   support

      Normal       0.98      0.96      0.97        57
    Abnormal       1.00      0.96      0.98        47
          MI       1.00      1.00      1.00        48
  History_MI       0.92      1.00      0.96        34

    accuracy                           0.98       186
   macro avg       0.98      0.98      0.98       186
weighted avg       0.98      0.98      0.98       186

Confusion Matrix:
[[55  0  0  2]
 [ 1 45  0  1]
 [ 0  0 48  0]
 [ 0  0  0 34]]

XGBoost accuracy improved from 0.00% to 97.85%. Saving model...

Training and evaluating LightGBM...
/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.
  warnings.warn(
/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.
  warnings.warn(
LightGBM Accuracy: 97.85%

Classification Report:
              precision    recall  f1-score   support

      Normal       0.98      0.96      0.97        57
    Abnormal       1.00      0.96      0.98        47
          MI       1.00      1.00      1.00        48
  History_MI       0.92      1.00      0.96        34

    accuracy                           0.98       186
   macro avg       0.98      0.98      0.98       186
weighted avg       0.98      0.98      0.98       186

Confusion Matrix:
[[55  0  0  2]
 [ 1 45  0  1]
 [ 0  0 48  0]
 [ 0  0  0 34]]

LightGBM accuracy improved from 0.00% to 97.85%. Saving model...

----------------------------------------------------------------------------------------------------------------------------------------------------
✅ Previously saved best validation accuracy: 0.9624
✅ Found saved best model. Loading weights from /content/drive/MyDrive/CIP/MODEL/best_model.h5
📌 Training will continue from last best validation accuracy: 0.9624
/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
Epoch 1/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 243s 10s/step - accuracy: 0.7477 - loss: 2.2620 - val_accuracy: 0.4086 - val_loss: 18.3593
Epoch 2/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 237s 10s/step - accuracy: 0.8334 - loss: 1.3092 - val_accuracy: 0.8548 - val_loss: 1.1973
Epoch 3/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 237s 10s/step - accuracy: 0.9031 - loss: 0.5343 - val_accuracy: 0.7473 - val_loss: 11.1264
Epoch 4/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 246s 10s/step - accuracy: 0.9214 - loss: 0.4895 - val_accuracy: 0.7419 - val_loss: 4.6724
Epoch 5/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 249s 10s/step - accuracy: 0.8641 - loss: 0.7612 - val_accuracy: 0.3387 - val_loss: 15.4002
Epoch 6/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 238s 10s/step - accuracy: 0.8898 - loss: 0.5959 - val_accuracy: 0.3656 - val_loss: 9.5631
Epoch 7/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 239s 10s/step - accuracy: 0.8902 - loss: 0.5222 - val_accuracy: 0.6398 - val_loss: 4.4602
Epoch 8/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 241s 10s/step - accuracy: 0.9292 - loss: 0.4797 - val_accuracy: 0.7097 - val_loss: 2.8450
Epoch 9/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 239s 10s/step - accuracy: 0.9051 - loss: 0.4502 - val_accuracy: 0.7043 - val_loss: 4.5172
Epoch 10/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 262s 10s/step - accuracy: 0.9074 - loss: 0.3369 - val_accuracy: 0.7097 - val_loss: 4.2421
Epoch 11/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 238s 10s/step - accuracy: 0.8909 - loss: 0.5690 - val_accuracy: 0.2634 - val_loss: 44.0207
Epoch 12/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 239s 10s/step - accuracy: 0.8930 - loss: 0.6696 - val_accuracy: 0.6183 - val_loss: 5.8479
Epoch 13/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 239s 10s/step - accuracy: 0.8433 - loss: 0.9017 - val_accuracy: 0.1828 - val_loss: 47.9613
Epoch 14/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 239s 10s/step - accuracy: 0.8933 - loss: 0.4552 - val_accuracy: 0.2097 - val_loss: 27.7912
Epoch 15/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 239s 10s/step - accuracy: 0.8929 - loss: 0.4009 - val_accuracy: 0.2742 - val_loss: 19.3369
Epoch 16/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 238s 10s/step - accuracy: 0.9225 - loss: 0.4068 - val_accuracy: 0.8602 - val_loss: 0.7422
Epoch 17/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 237s 10s/step - accuracy: 0.9222 - loss: 0.3018 - val_accuracy: 0.9409 - val_loss: 0.2955
Epoch 18/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 239s 10s/step - accuracy: 0.9526 - loss: 0.2006 - val_accuracy: 0.8118 - val_loss: 1.4347
Epoch 19/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 238s 10s/step - accuracy: 0.9175 - loss: 0.3685 - val_accuracy: 0.3495 - val_loss: 11.9703
Epoch 20/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 241s 10s/step - accuracy: 0.9254 - loss: 0.3094 - val_accuracy: 0.3602 - val_loss: 8.4711
Epoch 21/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 239s 10s/step - accuracy: 0.9334 - loss: 0.2470 - val_accuracy: 0.5914 - val_loss: 3.1813
Epoch 22/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 261s 10s/step - accuracy: 0.9526 - loss: 0.1651 - val_accuracy: 0.3710 - val_loss: 10.9245
Epoch 23/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 238s 10s/step - accuracy: 0.9514 - loss: 0.1323 - val_accuracy: 0.4677 - val_loss: 7.4759
Epoch 24/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 237s 10s/step - accuracy: 0.9540 - loss: 0.1829 - val_accuracy: 0.8011 - val_loss: 1.6402
Epoch 25/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 239s 10s/step - accuracy: 0.9491 - loss: 0.1829 - val_accuracy: 0.7742 - val_loss: 3.3016
Epoch 26/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 237s 10s/step - accuracy: 0.9700 - loss: 0.1024 - val_accuracy: 0.8387 - val_loss: 1.7333
Epoch 27/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 240s 10s/step - accuracy: 0.9574 - loss: 0.1410 - val_accuracy: 0.7473 - val_loss: 2.3771
Epoch 28/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 0s 9s/step - accuracy: 0.9119 - loss: 0.4163WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 

🏆 Validation accuracy improved from 0.9624 to 0.9892. Saving model...
24/24 ━━━━━━━━━━━━━━━━━━━━ 262s 10s/step - accuracy: 0.9126 - loss: 0.4131 - val_accuracy: 0.9892 - val_loss: 0.0590
Epoch 29/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 249s 10s/step - accuracy: 0.9455 - loss: 0.1689 - val_accuracy: 0.8495 - val_loss: 1.1301
Epoch 30/30
24/24 ━━━━━━━━━━━━━━━━━━━━ 238s 10s/step - accuracy: 0.9418 - loss: 0.2742 - val_accuracy: 0.9516 - val_loss: 0.1349
WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
🏆 Final best validation accuracy achieved: 0.9892

WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
24/24 ━━━━━━━━━━━━━━━━━━━━ 38s 2s/step
6/6 ━━━━━━━━━━━━━━━━━━━━ 8s 1s/step

Training and evaluating SVM...
SVM Accuracy: 98.39%

Classification Report:
              precision    recall  f1-score   support

      Normal       1.00      1.00      1.00        57
    Abnormal       0.98      0.96      0.97        47
          MI       1.00      1.00      1.00        48
  History_MI       0.94      0.97      0.96        34

    accuracy                           0.98       186
   macro avg       0.98      0.98      0.98       186
weighted avg       0.98      0.98      0.98       186

Confusion Matrix:
[[57  0  0  0]
 [ 0 45  0  2]
 [ 0  0 48  0]
 [ 0  1  0 33]]

SVM accuracy improved from 96.24% to 98.39%. Saving model...

Training and evaluating K-NN...
K-NN Accuracy: 97.85%

Classification Report:
              precision    recall  f1-score   support

      Normal       0.98      1.00      0.99        57
    Abnormal       0.98      0.94      0.96        47
          MI       1.00      1.00      1.00        48
  History_MI       0.94      0.97      0.96        34

    accuracy                           0.98       186
   macro avg       0.98      0.98      0.98       186
weighted avg       0.98      0.98      0.98       186

Confusion Matrix:
[[57  0  0  0]
 [ 1 44  0  2]
 [ 0  0 48  0]
 [ 0  1  0 33]]

K-NN accuracy improved from 96.24% to 97.85%. Saving model...

Training and evaluating Decision Tree...
Decision Tree Accuracy: 96.24%

Classification Report:
              precision    recall  f1-score   support

      Normal       0.96      0.96      0.96        57
    Abnormal       0.96      0.94      0.95        47
          MI       0.96      1.00      0.98        48
  History_MI       0.97      0.94      0.96        34

    accuracy                           0.96       186
   macro avg       0.96      0.96      0.96       186
weighted avg       0.96      0.96      0.96       186

Confusion Matrix:
[[55  2  0  0]
 [ 2 44  0  1]
 [ 0  0 48  0]
 [ 0  0  2 32]]

Decision Tree accuracy improved from 93.01% to 96.24%. Saving model...

Training and evaluating Random Forest...
Random Forest Accuracy: 98.92%

Classification Report:
              precision    recall  f1-score   support

      Normal       0.98      1.00      0.99        57
    Abnormal       1.00      0.96      0.98        47
          MI       1.00      1.00      1.00        48
  History_MI       0.97      1.00      0.99        34

    accuracy                           0.99       186
   macro avg       0.99      0.99      0.99       186
weighted avg       0.99      0.99      0.99       186

Confusion Matrix:
[[57  0  0  0]
 [ 1 45  0  1]
 [ 0  0 48  0]
 [ 0  0  0 34]]

Random Forest accuracy improved from 97.31% to 98.92%. Saving model...

Training and evaluating Naive Bayes...
Naive Bayes Accuracy: 97.31%

Classification Report:
              precision    recall  f1-score   support

      Normal       0.98      1.00      0.99        57
    Abnormal       0.96      0.94      0.95        47
          MI       1.00      1.00      1.00        48
  History_MI       0.94      0.94      0.94        34

    accuracy                           0.97       186
   macro avg       0.97      0.97      0.97       186
weighted avg       0.97      0.97      0.97       186

Confusion Matrix:
[[57  0  0  0]
 [ 1 44  0  2]
 [ 0  0 48  0]
 [ 0  2  0 32]]

Naive Bayes accuracy improved from 96.24% to 97.31%. Saving model...

Training and evaluating XGBoost...
XGBoost Accuracy: 98.92%

Classification Report:
              precision    recall  f1-score   support

      Normal       0.98      1.00      0.99        57
    Abnormal       1.00      0.96      0.98        47
          MI       1.00      1.00      1.00        48
  History_MI       0.97      1.00      0.99        34

    accuracy                           0.99       186
   macro avg       0.99      0.99      0.99       186
weighted avg       0.99      0.99      0.99       186

Confusion Matrix:
[[57  0  0  0]
 [ 1 45  0  1]
 [ 0  0 48  0]
 [ 0  0  0 34]]

XGBoost accuracy improved from 97.85% to 98.92%. Saving model...

Training and evaluating LightGBM...
/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.
  warnings.warn(
/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.
  warnings.warn(
LightGBM Accuracy: 99.46%

Classification Report:
              precision    recall  f1-score   support

      Normal       1.00      1.00      1.00        57
    Abnormal       1.00      0.98      0.99        47
          MI       1.00      1.00      1.00        48
  History_MI       0.97      1.00      0.99        34

    accuracy                           0.99       186
   macro avg       0.99      0.99      0.99       186
weighted avg       0.99      0.99      0.99       186

Confusion Matrix:
[[57  0  0  0]
 [ 0 46  0  1]
 [ 0  0 48  0]
 [ 0  0  0 34]]

LightGBM accuracy improved from 97.85% to 99.46%. Saving model...
--------------------------------------------------------------------------------------------------------------------------
WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
24/24 ━━━━━━━━━━━━━━━━━━━━ 40s 2s/step
6/6 ━━━━━━━━━━━━━━━━━━━━ 10s 2s/step

🔷 Training and evaluating SVM...

✅ SVM Accuracy: 98.92%

📊 Classification Report:
              precision    recall  f1-score   support

      Normal       1.00      1.00      1.00        57
    Abnormal       0.98      0.98      0.98        47
          MI       1.00      1.00      1.00        48
  History_MI       0.97      0.97      0.97        34

    accuracy                           0.99       186
   macro avg       0.99      0.99      0.99       186
weighted avg       0.99      0.99      0.99       186


🆙 SVM accuracy improved from 98.39% to 98.92%. Saving model...

🔷 Training and evaluating K-NN...

✅ K-NN Accuracy: 97.85%

📊 Classification Report:
              precision    recall  f1-score   support

      Normal       0.97      1.00      0.98        57
    Abnormal       0.98      0.94      0.96        47
          MI       1.00      1.00      1.00        48
  History_MI       0.97      0.97      0.97        34

    accuracy                           0.98       186
   macro avg       0.98      0.98      0.98       186
weighted avg       0.98      0.98      0.98       186


⚠️ K-NN accuracy did not improve. Previous: 97.85%, Current: 97.85%

🔷 Training and evaluating Decision Tree...

✅ Decision Tree Accuracy: 97.85%

📊 Classification Report:
              precision    recall  f1-score   support

      Normal       0.98      0.96      0.97        57
    Abnormal       1.00      0.96      0.98        47
          MI       1.00      1.00      1.00        48
  History_MI       0.92      1.00      0.96        34

    accuracy                           0.98       186
   macro avg       0.98      0.98      0.98       186
weighted avg       0.98      0.98      0.98       186


🆙 Decision Tree accuracy improved from 96.24% to 97.85%. Saving model...

🔷 Training and evaluating Random Forest...

✅ Random Forest Accuracy: 98.39%

📊 Classification Report:
              precision    recall  f1-score   support

      Normal       0.98      1.00      0.99        57
    Abnormal       1.00      0.94      0.97        47
          MI       1.00      1.00      1.00        48
  History_MI       0.94      1.00      0.97        34

    accuracy                           0.98       186
   macro avg       0.98      0.98      0.98       186
weighted avg       0.98      0.98      0.98       186


⚠️ Random Forest accuracy did not improve. Previous: 98.92%, Current: 98.39%

🔷 Training and evaluating Naive Bayes...

✅ Naive Bayes Accuracy: 97.31%

📊 Classification Report:
              precision    recall  f1-score   support

      Normal       0.98      1.00      0.99        57
    Abnormal       0.96      0.94      0.95        47
          MI       1.00      1.00      1.00        48
  History_MI       0.94      0.94      0.94        34

    accuracy                           0.97       186
   macro avg       0.97      0.97      0.97       186
weighted avg       0.97      0.97      0.97       186


⚠️ Naive Bayes accuracy did not improve. Previous: 97.31%, Current: 97.31%

🔷 Training and evaluating XGBoost...
/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [18:14:51] WARNING: /workspace/src/learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)

✅ XGBoost Accuracy: 98.92%

📊 Classification Report:
              precision    recall  f1-score   support

      Normal       0.98      1.00      0.99        57
    Abnormal       1.00      0.96      0.98        47
          MI       1.00      1.00      1.00        48
  History_MI       0.97      1.00      0.99        34

    accuracy                           0.99       186
   macro avg       0.99      0.99      0.99       186
weighted avg       0.99      0.99      0.99       186


⚠️ XGBoost accuracy did not improve. Previous: 98.92%, Current: 98.92%

🔷 Training and evaluating LightGBM...
/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.
  warnings.warn(
/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.
  warnings.warn(

✅ LightGBM Accuracy: 99.46%

📊 Classification Report:
              precision    recall  f1-score   support

      Normal       1.00      1.00      1.00        57
    Abnormal       1.00      0.98      0.99        47
          MI       1.00      1.00      1.00        48
  History_MI       0.97      1.00      0.99        34

    accuracy                           0.99       186
   macro avg       0.99      0.99      0.99       186
weighted avg       0.99      0.99      0.99       186


⚠️ LightGBM accuracy did not improve. Previous: 99.46%, Current: 99.46%

🚀 All models evaluated and best models saved successfully!
